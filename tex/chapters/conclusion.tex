\chapter{Conclusion}\label{ch:conclusion}


\begin{itemize}
    \item By training the FNO on a coarse grid and evaluate on a fine grid, the run time is XX times faster, while maintaining the same accuracy.
    \item Long-term prediction: the FNO can predict the solution for a longer time than the training time.
    It was demonstrated that training on a coarse grid was not suitable to facilitate a long-term prediction for a fine grid.
    %However, I do not have good results for training on coarse grid, predicting for a fine grid for long-term prediction.
    \item Long-term prediction: the FNO model outperforms the CNN model for long-term prediction.
    \item Grid independence: when training on a coarse grid and evaluating on a fine grid, the predictions by the FNO is much better than the predictions by the CNN. Aligning with the theory that FNOs are grid independent.
    \item Efficiency: CNN is faster than FNO, but FNO is more accurate. Which we prefer depends on the application.
    \item CNN has shown potential for many of the same abilities as the FNO - especially in the 1D case.
    \item Some of the theoretical advantages of the FNO are better realized in the 2D case than in the 1D case.
    \item Which model we choose is depending on the application.
\end{itemize}



%FNO's ability to generalize to unseen data.


